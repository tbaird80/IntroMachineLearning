{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b204aa8-62c2-443a-a76a-072dad3dc33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\thoma\\PycharmProjects\\IntroMachineLearning\\Project1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(\"Current Working Directory:\", cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "881330ab-e2e4-4477-aef2-e86634cfd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def dataSourcing(dataName):\n",
    "    \"\"\"\n",
    "\n",
    "    @param dataName:\n",
    "    @return:\n",
    "    \"\"\"\n",
    "\n",
    "    featurePath = dataName + \"/featureData.csv\"\n",
    "    targetPath = dataName + \"/targetData.csv\"\n",
    "\n",
    "    if dataName == 'BreastCancer':\n",
    "        # check if file path exists, read from file if so, otherwise grab from online repo\n",
    "        if os.path.exists(featurePath) & os.path.exists(targetPath):\n",
    "            print(dataName + \" data exists, reading from csv\")\n",
    "\n",
    "            # read from local directory\n",
    "            dataFeatures = pd.read_csv(featurePath, index_col=0)\n",
    "            dataTargets = pd.read_csv(targetPath, index_col=0)\n",
    "\n",
    "        else:\n",
    "            print(dataName + \"data does not exist, reading from source\")\n",
    "\n",
    "            # fetch dataset\n",
    "            breast_cancer_wisconsin_original = fetch_ucirepo(id=15)\n",
    "\n",
    "            # data (as pandas dataframes)\n",
    "            dataFeatures = pd.DataFrame(breast_cancer_wisconsin_original.data.features)\n",
    "            dataTargets = pd.DataFrame(breast_cancer_wisconsin_original.data.targets)\n",
    "\n",
    "            # write to local directory\n",
    "            dataFeatures.to_csv(featurePath, index=True)\n",
    "            dataTargets.to_csv(targetPath, index=True)\n",
    "\n",
    "        # remove NAs\n",
    "        dataFeatures = dataFeatures.dropna()\n",
    "\n",
    "        # assign types to all columns\n",
    "        dataFeatures.loc[:, 'Clump_thickness'] = dataFeatures['Clump_thickness'].astype(float)\n",
    "        dataFeatures.loc[:, 'Uniformity_of_cell_size'] = dataFeatures['Uniformity_of_cell_size'].astype(float)\n",
    "        dataFeatures.loc[:, 'Uniformity_of_cell_shape'] = dataFeatures['Uniformity_of_cell_shape'].astype(float)\n",
    "        dataFeatures.loc[:, 'Marginal_adhesion'] = dataFeatures['Marginal_adhesion'].astype(float)\n",
    "        dataFeatures.loc[:, 'Single_epithelial_cell_size'] = dataFeatures['Single_epithelial_cell_size'].astype(float)\n",
    "        dataFeatures.loc[:, 'Bare_nuclei'] = dataFeatures['Bare_nuclei'].astype(float)\n",
    "        dataFeatures.loc[:, 'Bland_chromatin'] = dataFeatures['Bland_chromatin'].astype(float)\n",
    "        dataFeatures.loc[:, 'Normal_nucleoli'] = dataFeatures['Normal_nucleoli'].astype(float)\n",
    "        dataFeatures.loc[:, 'Mitoses'] = dataFeatures['Mitoses'].astype(float)\n",
    "\n",
    "        # set the name of the target column\n",
    "        dataTargets = dataTargets.loc[dataFeatures.index.tolist()]\n",
    "        dataTargets.columns = ['Class']\n",
    "\n",
    "    elif dataName == 'CarEval':\n",
    "        # check if file path exists, read from file if so, otherwise grab from online repo\n",
    "        if os.path.exists(featurePath) & os.path.exists(targetPath):\n",
    "            print(dataName + \" data exists, reading from csv\")\n",
    "\n",
    "            # read from local directory\n",
    "            dataFeatures = pd.read_csv(featurePath, index_col=0)\n",
    "            dataTargets = pd.read_csv(targetPath, index_col=0)\n",
    "\n",
    "        else:\n",
    "            print(dataName + \" data does not exist, reading from source\")\n",
    "\n",
    "            # fetch dataset\n",
    "            car_evaluation = fetch_ucirepo(id=19)\n",
    "\n",
    "            # store relevant data (as pandas dataframes)\n",
    "            dataFeatures = pd.DataFrame(car_evaluation.data.features)\n",
    "            dataTargets = pd.DataFrame(car_evaluation.data.targets)\n",
    "\n",
    "            # write to the local directory\n",
    "            dataFeatures.to_csv(featurePath, index=True)\n",
    "            dataTargets.to_csv(targetPath, index=True)\n",
    "\n",
    "        # assign types to all columns\n",
    "        dataFeatures = pd.get_dummies(dataFeatures).astype(bool)\n",
    "\n",
    "        # set the name of the target column\n",
    "        dataTargets.columns = ['Class']\n",
    "\n",
    "    elif dataName == 'CongressVoting':\n",
    "        # check if file path exists, read from file if so, otherwise grab from online repo\n",
    "        if os.path.exists(featurePath) & os.path.exists(targetPath):\n",
    "            print(dataName + \" data exists, reading from csv\")\n",
    "\n",
    "            # read from local directory\n",
    "            dataFeatures = pd.read_csv(featurePath, index_col=0)\n",
    "            dataTargets = pd.read_csv(targetPath, index_col=0)\n",
    "\n",
    "        else:\n",
    "            print(dataName + \" data does not exist, reading from source\")\n",
    "\n",
    "            # fetch dataset\n",
    "            congressional_voting_records = fetch_ucirepo(id=105)\n",
    "\n",
    "            # store relevant data (as pandas dataframes)\n",
    "            dataFeatures = pd.DataFrame(congressional_voting_records.data.features)\n",
    "            dataTargets = pd.DataFrame(congressional_voting_records.data.targets)\n",
    "\n",
    "            # write to the local directory\n",
    "            dataFeatures.to_csv(featurePath, index=True)\n",
    "            dataTargets.to_csv(targetPath, index=True)\n",
    "\n",
    "        # reset the data to be integers. helps to account for abstain votes which will be 0's\n",
    "        dataFeatures = dataFeatures.replace({'y': 1, 'n': -1})\n",
    "        dataFeatures = dataFeatures.fillna(0)\n",
    "\n",
    "        # assign types to all columns\n",
    "        dataFeatures.loc[:, 'handicapped-infants'] = dataFeatures['handicapped-infants'].astype(int)\n",
    "        dataFeatures.loc[:, 'water-project-cost-sharing'] = dataFeatures['water-project-cost-sharing'].astype(int)\n",
    "        dataFeatures.loc[:, 'adoption-of-the-budget-resolution'] = dataFeatures[\n",
    "            'adoption-of-the-budget-resolution'].astype(int)\n",
    "        dataFeatures.loc[:, 'physician-fee-freeze'] = dataFeatures['physician-fee-freeze'].astype(int)\n",
    "        dataFeatures.loc[:, 'el-salvador-aid'] = dataFeatures['el-salvador-aid'].astype(int)\n",
    "        dataFeatures.loc[:, 'religious-groups-in-schools'] = dataFeatures['religious-groups-in-schools'].astype(int)\n",
    "        dataFeatures.loc[:, 'anti-satellite-test-ban'] = dataFeatures['anti-satellite-test-ban'].astype(int)\n",
    "        dataFeatures.loc[:, 'aid-to-nicaraguan-contras'] = dataFeatures['aid-to-nicaraguan-contras'].astype(int)\n",
    "        dataFeatures.loc[:, 'mx-missile'] = dataFeatures['mx-missile'].astype(int)\n",
    "        dataFeatures.loc[:, 'immigration'] = dataFeatures['immigration'].astype(int)\n",
    "        dataFeatures.loc[:, 'synfuels-corporation-cutback'] = dataFeatures['synfuels-corporation-cutback'].astype(int)\n",
    "        dataFeatures.loc[:, 'education-spending'] = dataFeatures['education-spending'].astype(int)\n",
    "        dataFeatures.loc[:, 'superfund-right-to-sue'] = dataFeatures['superfund-right-to-sue'].astype(int)\n",
    "        dataFeatures.loc[:, 'crime'] = dataFeatures['crime'].astype(int)\n",
    "        dataFeatures.loc[:, 'duty-free-exports'] = dataFeatures['duty-free-exports'].astype(int)\n",
    "        dataFeatures.loc[:, 'export-administration-act-south-africa'] = dataFeatures[\n",
    "            'export-administration-act-south-africa'].astype(int)\n",
    "\n",
    "        # set the name of the target column\n",
    "        dataTargets = dataTargets.loc[dataFeatures.index.tolist()]\n",
    "        dataTargets.columns = ['Class']\n",
    "\n",
    "    elif dataName == 'Abalone':\n",
    "        # check if file path exists, read from file if so, otherwise grab from online repo\n",
    "        if os.path.exists(featurePath) & os.path.exists(targetPath):\n",
    "            print(dataName + \" data exists, reading from csv\")\n",
    "\n",
    "            # read from local directory\n",
    "            dataFeatures = pd.read_csv(featurePath, index_col=0)\n",
    "            dataTargets = pd.read_csv(targetPath, index_col=0)\n",
    "\n",
    "        else:\n",
    "            print(dataName + \" data does not exist, reading from source\")\n",
    "\n",
    "            # fetch dataset\n",
    "            abalone = fetch_ucirepo(id=1)\n",
    "\n",
    "            # store relevant data (as pandas dataframes)\n",
    "            dataFeatures = pd.DataFrame(abalone.data.features)\n",
    "            dataTargets = pd.DataFrame(abalone.data.targets)\n",
    "\n",
    "            # write to the local directory\n",
    "            dataFeatures.to_csv(featurePath, index=True)\n",
    "            dataTargets.to_csv(targetPath, index=True)\n",
    "\n",
    "        # assign types to all columns\n",
    "        # performing one hot encoding for the sex column and then dropping the original column\n",
    "        dataFeatures_Sex = dataFeatures['Sex']\n",
    "        dataFeatures_Sex = pd.get_dummies(dataFeatures_Sex).astype(bool)\n",
    "        dataFeatures = dataFeatures.join(dataFeatures_Sex)\n",
    "        dataFeatures = dataFeatures.drop(columns='Sex')\n",
    "\n",
    "        # normalize the rest\n",
    "        dataFeatures.loc[:, 'Length'] = dataFeatures['Length'].astype(float)\n",
    "        dataFeatures.loc[:, 'Diameter'] = dataFeatures['Diameter'].astype(float)\n",
    "        dataFeatures.loc[:, 'Height'] = dataFeatures['Height'].astype(float)\n",
    "        dataFeatures.loc[:, 'Whole_weight'] = dataFeatures['Whole_weight'].astype(float)\n",
    "        dataFeatures.loc[:, 'Shucked_weight'] = dataFeatures['Shucked_weight'].astype(float)\n",
    "        dataFeatures.loc[:, 'Viscera_weight'] = dataFeatures['Viscera_weight'].astype(float)\n",
    "        dataFeatures.loc[:, 'Shell_weight'] = dataFeatures['Shell_weight'].astype(float)\n",
    "\n",
    "        # set the name of the target column\n",
    "        dataTargets = dataTargets.loc[dataFeatures.index.tolist()]\n",
    "        dataTargets.columns = ['Class']\n",
    "\n",
    "    elif dataName == 'ComputerHardware':\n",
    "        # check if file path exists, read from file if so, otherwise grab from online repo\n",
    "        if os.path.exists(featurePath) & os.path.exists(targetPath):\n",
    "            print(dataName + \"data exists, reading from csv\")\n",
    "\n",
    "            # read from local directory\n",
    "            dataFeatures = pd.read_csv(featurePath, index_col=0)\n",
    "            dataTargets = pd.read_csv(targetPath, index_col=0)\n",
    "\n",
    "        else:\n",
    "            print(dataName + \"data does not exist, reading from source\")\n",
    "\n",
    "            # fetch dataset\n",
    "            computer_hardware = fetch_ucirepo(id=29)\n",
    "\n",
    "            # data (as pandas dataframes)\n",
    "            dataFeatures = pd.DataFrame(computer_hardware.data.features)\n",
    "            dataTargets = pd.DataFrame(dataFeatures['PRP'])\n",
    "\n",
    "            # write to the local directory\n",
    "            dataFeatures.to_csv(featurePath, index=True)\n",
    "            dataTargets.to_csv(targetPath, index=True)\n",
    "\n",
    "        # drop the columns that we do not need\n",
    "        dataFeatures = dataFeatures.drop(columns=['VendorName', 'ModelName', 'PRP', 'ERP'])\n",
    "\n",
    "        # assign types to all columns, normalizing these\n",
    "        dataFeatures.loc[:, 'MYCT'] = dataFeatures['MYCT'].astype(float)\n",
    "        dataFeatures.loc[:, 'MMIN'] = dataFeatures['MMIN'].astype(float)\n",
    "        dataFeatures.loc[:, 'MMAX'] = dataFeatures['MMAX'].astype(float)\n",
    "        dataFeatures.loc[:, 'CACH'] = dataFeatures['CACH'].astype(float)\n",
    "        dataFeatures.loc[:, 'CHMIN'] = dataFeatures['CHMIN'].astype(float)\n",
    "        dataFeatures.loc[:, 'CHMAX'] = dataFeatures['CHMAX'].astype(float)\n",
    "\n",
    "        # set the name of the target column\n",
    "        dataTargets = dataTargets.loc[dataFeatures.index.tolist()]\n",
    "        dataTargets.columns = ['Class']\n",
    "\n",
    "    elif dataName == 'ForestFires':\n",
    "        # check if file path exists, read from file if so, otherwise grab from online repo\n",
    "        if os.path.exists(featurePath) & os.path.exists(targetPath):\n",
    "            print(dataName + \"data exists, reading from csv\")\n",
    "\n",
    "            # read from local directory\n",
    "            dataFeatures = pd.read_csv(featurePath, index_col=0)\n",
    "            dataTargets = pd.read_csv(targetPath, index_col=0)\n",
    "\n",
    "        else:\n",
    "            print(dataName + \"data does not exist, reading from source\")\n",
    "\n",
    "            # fetch dataset\n",
    "            forest_fires = fetch_ucirepo(id=162)\n",
    "\n",
    "            # data (as pandas dataframes)\n",
    "            dataFeatures = pd.DataFrame(forest_fires.data.features)\n",
    "            dataTargets = pd.DataFrame(forest_fires.data.targets)\n",
    "\n",
    "            # write to the local directory\n",
    "            dataFeatures.to_csv(featurePath, index=True)\n",
    "            dataTargets.to_csv(targetPath, index=True)\n",
    "\n",
    "        # assign types to all columns\n",
    "        # setting these to integers as they are ordinal values\n",
    "        dataFeatures.loc[:, 'X'] = dataFeatures['X'].astype(int)\n",
    "        dataFeatures.loc[:, 'Y'] = dataFeatures['Y'].astype(int)\n",
    "\n",
    "        # adjust these date values to relative integer values\n",
    "        month_dict = {\n",
    "            'jan': 1,\n",
    "            'feb': 2,\n",
    "            'mar': 3,\n",
    "            'apr': 4,\n",
    "            'may': 5,\n",
    "            'jun': 6,\n",
    "            'jul': 7,\n",
    "            'aug': 8,\n",
    "            'sep': 9,\n",
    "            'oct': 10,\n",
    "            'nov': 11,\n",
    "            'dec': 12\n",
    "        }\n",
    "        # Replace month names with integer values\n",
    "        dataFeatures.loc[:, 'month'] = dataFeatures['month'].replace(month_dict)\n",
    "        dataFeatures.loc[:, 'month'] = dataFeatures['X'].astype(int)\n",
    "\n",
    "        day_dict = {\n",
    "            'mon': 1,\n",
    "            'tue': 2,\n",
    "            'wed': 3,\n",
    "            'thu': 4,\n",
    "            'fri': 5,\n",
    "            'sat': 6,\n",
    "            'sun': 7\n",
    "        }\n",
    "        # Replace month names with integer values\n",
    "        dataFeatures.loc[:, 'day'] = dataFeatures['day'].replace(day_dict)\n",
    "        dataFeatures.loc[:, 'day'] = dataFeatures['day'].astype(int)\n",
    "\n",
    "        # normalize these\n",
    "        dataFeatures.loc[:, 'FFMC'] = dataFeatures['FFMC'].astype(float)\n",
    "        dataFeatures.loc[:, 'DMC'] = dataFeatures['DMC'].astype(float)\n",
    "        dataFeatures.loc[:, 'DC'] = dataFeatures['DC'].astype(float)\n",
    "        dataFeatures.loc[:, 'ISI'] = dataFeatures['ISI'].astype(float)\n",
    "        dataFeatures.loc[:, 'temp'] = dataFeatures['temp'].astype(float)\n",
    "        dataFeatures.loc[:, 'RH'] = dataFeatures['RH'].astype(float)\n",
    "        dataFeatures.loc[:, 'wind'] = dataFeatures['wind'].astype(float)\n",
    "        dataFeatures.loc[:, 'rain'] = dataFeatures['rain'].astype(float)\n",
    "\n",
    "        # set the name of the target column\n",
    "        dataTargets = dataTargets.loc[dataFeatures.index.tolist()]\n",
    "        dataTargets.columns = ['Class']\n",
    "        dataTargets.loc[:, 'Class'] = np.log1p(dataTargets['Class'])\n",
    "\n",
    "    return dataFeatures, dataTargets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d1b91f68-b06f-4591-bc55-2c3f3731bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CarEval data exists, reading from csv\n"
     ]
    }
   ],
   "source": [
    "currentDataSet = 'CarEval'\n",
    "features, targets = dataSourcing(currentDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2ec46a0-31d9-412d-a56f-66495ab7eaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2        444\n",
       "4        239\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>k</th>\n",
       "      <th>e</th>\n",
       "      <th>s</th>\n",
       "      <th>AveragePerformance</th>\n",
       "      <th>TestsRun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959124</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.954745</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942336</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.938686</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902920</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p  k  e  s  AveragePerformance  TestsRun\n",
       "7  2  4  1  1            0.959124        10\n",
       "3  1  4  1  1            0.954745        10\n",
       "1  1  2  1  1            0.942336        10\n",
       "4  2  1  1  1            0.938686        10\n",
       "2  1  3  1  1            0.902920        10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>testID</th>\n",
       "      <th>nearestNeighbors</th>\n",
       "      <th>expectedValue</th>\n",
       "      <th>actualValue</th>\n",
       "      <th>correctAssignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1</td>\n",
       "      <td>[314, 637, 19, 309]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1</td>\n",
       "      <td>[314, 19, 309, 637]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>[314, 19, 637, 309]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1</td>\n",
       "      <td>[19, 637, 116, 489]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>1</td>\n",
       "      <td>[314, 309, 637, 19]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>5</td>\n",
       "      <td>[691, 435, 522, 316]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5</td>\n",
       "      <td>[296, 60, 530, 67]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>5</td>\n",
       "      <td>[691, 361, 73, 255]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>5</td>\n",
       "      <td>[691, 56, 259, 60]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>5</td>\n",
       "      <td>[522, 691, 530, 296]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2730 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     testID      nearestNeighbors  expectedValue  actualValue  \\\n",
       "684       1   [314, 637, 19, 309]              2            2   \n",
       "396       1   [314, 19, 309, 637]              2            2   \n",
       "35        1   [314, 19, 637, 309]              2            2   \n",
       "423       1   [19, 637, 116, 489]              2            2   \n",
       "324       1   [314, 309, 637, 19]              2            2   \n",
       "..      ...                   ...            ...          ...   \n",
       "658       5  [691, 435, 522, 316]              4            4   \n",
       "668       5    [296, 60, 530, 67]              4            4   \n",
       "681       5   [691, 361, 73, 255]              4            4   \n",
       "696       5    [691, 56, 259, 60]              4            4   \n",
       "697       5  [522, 691, 530, 296]              4            4   \n",
       "\n",
       "     correctAssignment  \n",
       "684               True  \n",
       "396               True  \n",
       "35                True  \n",
       "423               True  \n",
       "324               True  \n",
       "..                 ...  \n",
       "658               True  \n",
       "668               True  \n",
       "681               True  \n",
       "696               True  \n",
       "697               True  \n",
       "\n",
       "[2730 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9597069597069597\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% correct</th>\n",
       "      <th>totalCases</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actualValue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.957746</td>\n",
       "      <td>1775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.136126</td>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             % correct  totalCases\n",
       "actualValue                       \n",
       "2            96.957746        1775\n",
       "4            94.136126         955"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "  &    0 \\\\\n",
      "Class &      \\\\\n",
      "\\midrule\n",
      "2 &  444 \\\\\n",
      "4 &  239 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  p &  k &  e &  s &  AveragePerformance &  TestsRun \\\\\n",
      "\\midrule\n",
      "7 &  2 &  4 &  1 &  1 &               0.959 &        10 \\\\\n",
      "3 &  1 &  4 &  1 &  1 &               0.955 &        10 \\\\\n",
      "1 &  1 &  2 &  1 &  1 &               0.942 &        10 \\\\\n",
      "4 &  2 &  1 &  1 &  1 &               0.939 &        10 \\\\\n",
      "2 &  1 &  3 &  1 &  1 &               0.903 &        10 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  \\% correct &  totalCases \\\\\n",
      "actualValue &            &             \\\\\n",
      "\\midrule\n",
      "2           &     96.958 &        1775 \\\\\n",
      "4           &     94.136 &         955 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_56212\\76609268.py:26: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(targetsSummary.to_latex(index=True,\n",
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_56212\\76609268.py:30: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(parameterTuningOutput.to_latex(index=True,\n",
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_56212\\76609268.py:34: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(performanceByClassSuccess.to_latex(index=True,\n"
     ]
    }
   ],
   "source": [
    "# check summary of the targets\n",
    "targetsSummary = targets.value_counts()\n",
    "display(targetsSummary)\n",
    "\n",
    "tuningFilePath = currentDataSet + '/KEEPTestCases/ParameterTuningFile.csv'\n",
    "crossValFilePath = currentDataSet + '/KEEPTestCases/CrossValidationTestFile.csv'\n",
    "\n",
    "parameterTuningOutput = pd.read_csv(tuningFilePath, index_col=0)\n",
    "parameterTuningOutput = parameterTuningOutput.sort_values(by = ['AveragePerformance'], ascending = False)\n",
    "\n",
    "crossValidationOutput = pd.read_csv(crossValFilePath, index_col=0)\n",
    "\n",
    "display(parameterTuningOutput)\n",
    "display(crossValidationOutput)\n",
    "\n",
    "print(crossValidationOutput['correctAssignment'].mean())\n",
    "\n",
    "performanceByClassSuccess = pd.DataFrame(crossValidationOutput.groupby('actualValue')['correctAssignment'].mean())\n",
    "performanceByClassSuccess.columns = ['% correct']\n",
    "performanceByClassSuccess.loc[:,'% correct'] = performanceByClassSuccess['% correct'] * 100\n",
    "performanceByClassCount = pd.DataFrame(crossValidationOutput.groupby('actualValue')['correctAssignment'].count())\n",
    "performanceByClassCount.columns = ['totalCases']\n",
    "performanceByClassSuccess = performanceByClassSuccess.join(performanceByClassCount)\n",
    "display(performanceByClassSuccess)\n",
    "\n",
    "print(targetsSummary.to_latex(index=True,\n",
    "                  formatters={\"name\": str.upper},\n",
    "                  float_format=\"{:.3f}\".format,))\n",
    "\n",
    "print(parameterTuningOutput.to_latex(index=True,\n",
    "                  formatters={\"name\": str.upper},\n",
    "                  float_format=\"{:.3f}\".format,))\n",
    "\n",
    "print(performanceByClassSuccess.to_latex(index=True,\n",
    "                  formatters={\"name\": str.upper},\n",
    "                  float_format=\"{:.3f}\".format,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "963b9f9f-fb31-4153-a1a4-121df6e9325d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.111026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.398436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.418710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55%</th>\n",
       "      <td>0.865413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>1.100609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65%</th>\n",
       "      <td>1.400687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>1.728807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.024193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>2.284608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85%</th>\n",
       "      <td>2.576265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>3.267861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>3.906265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100%</th>\n",
       "      <td>6.995620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.995620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class\n",
       "count  517.000000\n",
       "mean     1.111026\n",
       "std      1.398436\n",
       "min      0.000000\n",
       "5%       0.000000\n",
       "10%      0.000000\n",
       "15%      0.000000\n",
       "20%      0.000000\n",
       "25%      0.000000\n",
       "30%      0.000000\n",
       "35%      0.000000\n",
       "40%      0.000000\n",
       "45%      0.000000\n",
       "50%      0.418710\n",
       "55%      0.865413\n",
       "60%      1.100609\n",
       "65%      1.400687\n",
       "70%      1.728807\n",
       "75%      2.024193\n",
       "80%      2.284608\n",
       "85%      2.576265\n",
       "90%      3.267861\n",
       "95%      3.906265\n",
       "100%     6.995620\n",
       "max      6.995620"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check summary of the targets\n",
    "featuresSummary = features.describe(percentiles=[.05, .1, .15, .2, .25,\n",
    "                                                 .30, .35, .40, .45, .5,\n",
    "                                                 .55, .60, .65, .70, .75,\n",
    "                                                 .8, .85, .9, .95, 1])\n",
    "targetsSummary = targets.describe(percentiles=[.05, .1, .15, .2, .25,\n",
    "                                                 .30, .35, .40, .45, .5,\n",
    "                                                 .55, .60, .65, .70, .75,\n",
    "                                                 .8, .85, .9, .95, 1])\n",
    "\n",
    "#print(featuresSummary)\n",
    "display(targetsSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d7f2f14-006b-4bab-b858-c00d11ca7d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_56212\\3146479482.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  parameterTuningOutput2.loc[:,'testID'] = (parameterTuningOutput2['testID']/2).astype(int)\n"
     ]
    }
   ],
   "source": [
    "crossValFilePath = currentDataSet + '/KEEPTestCases/CrossValidationTestFile.csv'\n",
    "\n",
    "parameterTuningOutput = pd.read_csv(crossValFilePath, index_col=0)\n",
    "\n",
    "parameterTuningOutput2 = parameterTuningOutput[parameterTuningOutput['testID'].isin([2, 4, 6, 8, 10])]\n",
    "\n",
    "parameterTuningOutput2.loc[:,'testID'] = (parameterTuningOutput2['testID']/2).astype(int)\n",
    "\n",
    "parameterTuningOutput2.to_csv(crossValFilePath, index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
